% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/estimateProbabilityThreshold.R
\name{estimateProbabilityThreshold}
\alias{estimateProbabilityThreshold}
\title{Calcalate metrics to estimate probability score treshold}
\usage{
estimateProbabilityThreshold(predictionsMM, returnPlot, interceptionPoint)
}
\arguments{
\item{predictionsMM}{Dataframe showing the top 3 classifications for the tumor (sub)type,
together with their probability scores and the original pathology label (originalCall)}

\item{returnPlot}{Do you want to obtain the data or (FALSE) or get the resulting plot (TRUE)?}

\item{interceptionPoint}{At which threshold would you like to draw the line that intersects the sensitivity and specificity lines?}
}
\value{
If returnPlot = FALSE: Dataframe containing the number of true positives ($TP), false positives ($FP),
true negatives ($TN) and false negatives ($FN) at different probability score tresholds.
Calculated from the metrics named above are the sensitivity ($sensitivity),
specificity ($specificity), precision ($precision) and recall ($recall).

If returnPlot = TRUE: Plot showing the sensitivity and specificity at the different probability score thresholds.
}
\description{
This function calculates the sensitivity, specificity, precision and recall at
different probability score thresholds for sample classification.
A sample is classified as positive when it receives a classification (prediction probability > threshold).
On the contrary, a sample is classified as negative when it does not receive a classification
(prediction probability < threshold). A true positive is a classified sample for which the prediction is
correct, a true negative a non-classified sample that had a wrong prediction.
}
